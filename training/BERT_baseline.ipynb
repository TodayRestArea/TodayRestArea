{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_baseline.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ctrIP1YtrWYtJkAyLvqYjNHtHudCKl1V","authorship_tag":"ABX9TyMXxpSuBv90GM6fIs3XyhQA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["[konlpy tag URL]()\n","\n","[korean stop words URL]()\n","\n","[model 참고 URL](https://zzaebok.github.io/deep_learning/nlp/Bert-for-classification/)"],"metadata":{"id":"U7rNAdyUxuwq"}},{"cell_type":"code","source":["!pip install konlpy\n","!pip install pytorch-transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0v18kTD0Wn-","executionInfo":{"status":"ok","timestamp":1642349034503,"user_tz":-540,"elapsed":5317,"user":{"displayName":"choi yerim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08643437384388876422"}},"outputId":"ef04932d-35e1-484d-8fe8-de0ec6a988d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n","Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.10.0+cu111)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (0.0.47)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.20.37)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.10.0.2)\n","Requirement already satisfied: botocore<1.24.0,>=1.23.37 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (1.23.37)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.5.0)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.37->boto3->pytorch-transformers) (1.25.11)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.37->boto3->pytorch-transformers) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.37->boto3->pytorch-transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import json\n","import ast\n","from konlpy.tag import Okt, Hannanum, Komoran, Kkma\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import random\n","import copy\n","import time\n","import gc\n","import re\n","import torch\n","\n","#import spacy\n","from tqdm import tqdm_notebook, tnrange\n","from tqdm.auto import tqdm\n","\n","tqdm.pandas(desc='Progress')\n","from collections import Counter\n","\n","from nltk import word_tokenize\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.autograd import Variable\n","from sklearn.metrics import f1_score\n","import os \n","from tensorflow import keras\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","from keras.layers import Dropout\n","from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n","from torch.optim import Adam\n","\n","# cross validation and metrics\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import f1_score\n","from torch.optim.optimizer import Optimizer\n","\n","from sklearn.preprocessing import StandardScaler\n","from multiprocessing import  Pool\n","from functools import partial\n","import numpy as np\n","from sklearn.decomposition import PCA\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import gc\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"9XMZQmq_HhF2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"fF7BlSUeoKaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH=\"/content/drive/MyDrive/학교 프로젝트/2022 슈퍼챌린지 SW 해커톤\""],"metadata":{"id":"aAr7GUJQsI4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_UxWXC8ELgl"},"outputs":[],"source":["def make_category(x):\n","  if int(x[1])<=3:\n","    return int(x[1])-1\n","  elif int(x[1])==4:\n","    return -1\n","  else:\n","    return int(x[1])-2\n","\n","with open(f\"{PATH}/data/train/감성대화말뭉치(최종데이터)_Training.json\",'r') as datafile:\n","    data=json.load(datafile)\n","train_data=pd.json_normalize(data)\n","train_data=pd.DataFrame(train_data)\n","data=\"\"\n","with open(f\"{PATH}/data/test/감성대화말뭉치(최종데이터)_Validation.json\",'r') as datafile:\n","    data=json.load(datafile)\n","test_data=pd.json_normalize(data)\n","test_data=pd.DataFrame(test_data)\n","\n","train_data[\"context\"]=train_data['talk.content.HS01']+\" \"+train_data['talk.content.HS02']+\" \"+train_data['talk.content.HS03']\n","test_data[\"context\"]=test_data['talk.content.HS01']+\" \"+test_data['talk.content.HS02']+\" \"+test_data['talk.content.HS03']\n","used_col=['profile.persona-id','profile.emotion.type', 'context']\n","for col in train_data.columns:\n","  if col not in used_col:\n","    train_data.drop(columns=col,inplace=True)\n","    test_data.drop(columns=col,inplace=True)\n","\n","train_data.columns=[\"id\",\"emotion\",\"context\"]\n","test_data.columns=[\"id\",\"emotion\",\"context\"]\n","\n","#train_data[\"context\"]=train_data[\"context\"].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","#train_data['context'].replace('', np.nan, inplace=True)\n","#test_data[\"context\"]=test_data[\"context\"].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","#test_data['context'].replace('', np.nan, inplace=True)\n","  \n","train_data[\"emotion\"]=train_data[\"emotion\"].apply(make_category)\n","train_data.drop(train_data[train_data[\"emotion\"]==-1].index,inplace=True)\n","test_data[\"emotion\"]=test_data[\"emotion\"].apply(make_category)\n","test_data.drop(test_data[test_data[\"emotion\"]==-1].index,inplace=True)"]},{"cell_type":"code","source":["class emotionDataset(Dataset):\n","    ''' context&emotion dataset '''\n","    def __init__(self, df):\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx, 2]\n","        label = self.df.iloc[idx, 1]\n","        return text, label\n","\n","emotion_train_dataset = emotionDataset(train_data)\n","train_loader = DataLoader(emotion_train_dataset, batch_size=2, shuffle=True, num_workers=2)"],"metadata":{"id":"CKI6qNqBzBJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(emotion_train_dataset),len(train_loader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27VGThDyae9r","executionInfo":{"status":"ok","timestamp":1642349047482,"user_tz":-540,"elapsed":24,"user":{"displayName":"choi yerim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08643437384388876422"}},"outputId":"11fb1a90-d0ce-44d5-f288-ffb802af2525"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["40827 20414\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',num_labels=5)\n","model.to(device)"],"metadata":{"id":"w9mS9LD9yq2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = Adam(model.parameters(), lr=1e-6)\n","\n","itr = 1\n","p_itr = 500\n","epochs = 4\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","\n","model.train()\n","for epoch in range(epochs):\n","    \n","    for text, label in train_loader:\n","        optimizer.zero_grad()\n","        # encoding and zero padding\n","        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","        sample = torch.tensor(padded_list)\n","        sample, label = sample.to(device), label.to(device)\n","        labels = torch.tensor(label)\n","        outputs = model(sample, labels=labels)\n","        loss, logits = outputs\n","\n","        pred = torch.argmax(F.softmax(logits), dim=1)\n","        correct = pred.eq(labels)\n","        total_correct += correct.sum().item()\n","        total_len += len(labels)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if itr % p_itr == 0:\n","            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n","            total_loss = 0\n","            total_len = 0\n","            total_correct = 0\n","\n","        itr+=1"],"metadata":{"id":"5p7U2mx2zfa4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642352308683,"user_tz":-540,"elapsed":3252587,"user":{"displayName":"choi yerim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08643437384388876422"}},"outputId":"673f35fb-2881-40b8-b2b9-2a457727ac0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch 1/1] Iteration 500 -> Train Loss: 1.7954, Accuracy: 0.177\n","[Epoch 1/1] Iteration 1000 -> Train Loss: 1.7913, Accuracy: 0.183\n","[Epoch 1/1] Iteration 1500 -> Train Loss: 1.7948, Accuracy: 0.167\n","[Epoch 1/1] Iteration 2000 -> Train Loss: 1.7873, Accuracy: 0.202\n","[Epoch 1/1] Iteration 2500 -> Train Loss: 1.7864, Accuracy: 0.197\n","[Epoch 1/1] Iteration 3000 -> Train Loss: 1.7798, Accuracy: 0.200\n","[Epoch 1/1] Iteration 3500 -> Train Loss: 1.7839, Accuracy: 0.192\n","[Epoch 1/1] Iteration 4000 -> Train Loss: 1.7708, Accuracy: 0.217\n","[Epoch 1/1] Iteration 4500 -> Train Loss: 1.7826, Accuracy: 0.205\n","[Epoch 1/1] Iteration 5000 -> Train Loss: 1.7462, Accuracy: 0.238\n","[Epoch 1/1] Iteration 5500 -> Train Loss: 1.6987, Accuracy: 0.278\n","[Epoch 1/1] Iteration 6000 -> Train Loss: 1.6769, Accuracy: 0.305\n","[Epoch 1/1] Iteration 6500 -> Train Loss: 1.6186, Accuracy: 0.326\n","[Epoch 1/1] Iteration 7000 -> Train Loss: 1.5620, Accuracy: 0.349\n","[Epoch 1/1] Iteration 7500 -> Train Loss: 1.5489, Accuracy: 0.378\n","[Epoch 1/1] Iteration 8000 -> Train Loss: 1.5163, Accuracy: 0.391\n","[Epoch 1/1] Iteration 8500 -> Train Loss: 1.4468, Accuracy: 0.446\n","[Epoch 1/1] Iteration 9000 -> Train Loss: 1.4145, Accuracy: 0.468\n","[Epoch 1/1] Iteration 9500 -> Train Loss: 1.4245, Accuracy: 0.453\n","[Epoch 1/1] Iteration 10000 -> Train Loss: 1.3644, Accuracy: 0.489\n","[Epoch 1/1] Iteration 10500 -> Train Loss: 1.3468, Accuracy: 0.495\n","[Epoch 1/1] Iteration 11000 -> Train Loss: 1.3732, Accuracy: 0.492\n","[Epoch 1/1] Iteration 11500 -> Train Loss: 1.2671, Accuracy: 0.532\n","[Epoch 1/1] Iteration 12000 -> Train Loss: 1.2440, Accuracy: 0.529\n","[Epoch 1/1] Iteration 12500 -> Train Loss: 1.2270, Accuracy: 0.544\n","[Epoch 1/1] Iteration 13000 -> Train Loss: 1.2033, Accuracy: 0.583\n","[Epoch 1/1] Iteration 13500 -> Train Loss: 1.2285, Accuracy: 0.565\n","[Epoch 1/1] Iteration 14000 -> Train Loss: 1.2162, Accuracy: 0.552\n","[Epoch 1/1] Iteration 14500 -> Train Loss: 1.1784, Accuracy: 0.582\n","[Epoch 1/1] Iteration 15000 -> Train Loss: 1.1496, Accuracy: 0.604\n","[Epoch 1/1] Iteration 15500 -> Train Loss: 1.1984, Accuracy: 0.569\n","[Epoch 1/1] Iteration 16000 -> Train Loss: 1.0898, Accuracy: 0.619\n","[Epoch 1/1] Iteration 16500 -> Train Loss: 1.0748, Accuracy: 0.630\n","[Epoch 1/1] Iteration 17000 -> Train Loss: 1.1188, Accuracy: 0.592\n","[Epoch 1/1] Iteration 17500 -> Train Loss: 1.1018, Accuracy: 0.605\n","[Epoch 1/1] Iteration 18000 -> Train Loss: 1.0941, Accuracy: 0.613\n","[Epoch 1/1] Iteration 18500 -> Train Loss: 1.1245, Accuracy: 0.602\n","[Epoch 1/1] Iteration 19000 -> Train Loss: 1.0742, Accuracy: 0.617\n","[Epoch 1/1] Iteration 19500 -> Train Loss: 1.0733, Accuracy: 0.617\n","[Epoch 1/1] Iteration 20000 -> Train Loss: 1.0566, Accuracy: 0.632\n"]}]},{"cell_type":"code","source":["# evaluation\n","model.eval()\n","\n","emotion_eval_dataset = emotionDataset(test_data)\n","eval_loader = DataLoader(emotion_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n","\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","for text, label in eval_loader:\n","    encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n","    padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n","    sample = torch.tensor(padded_list)\n","    sample, label = sample.to(device), label.to(device)\n","    labels = torch.tensor(label)\n","    outputs = model(sample, labels=labels)\n","    _, logits = outputs\n","\n","    pred = torch.argmax(F.softmax(logits), dim=1)\n","    correct = pred.eq(labels)\n","    total_correct += correct.sum().item()\n","    total_len += len(labels)\n","\n","print('Test accuracy: ', total_correct / total_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BwaUVALrkyJ-","executionInfo":{"status":"ok","timestamp":1642352427518,"user_tz":-540,"elapsed":118563,"user":{"displayName":"choi yerim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08643437384388876422"}},"outputId":"ebce830b-da58-4f01-ad64-f45f82e78c3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]},{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.6438891058180398\n"]}]},{"cell_type":"code","source":["# evaluation\n","device=\"cpu\"\n","model.to(device)\n","model.eval()\n","new_complaint=\"배고프다. 돈도 없고 춥고 배고파. 나는 거지야. 나는 아무짝에도 쓸모없는 사람인가봐.\"\n","encoded_list=[tokenizer.encode(new_complaint,add_special_tokens=True)]\n","padded_list=  [e + [0] * (512-len(e)) for e in encoded_list]\n","emotion_eval_dataset = emotionDataset(test_data)\n","eval_loader = DataLoader(emotion_eval_dataset, batch_size=2, shuffle=False, num_workers=2)\n","sample = torch.tensor(padded_list)\n","sample= sample.to(device)\n","label=torch.tensor([0])\n","label=label.to(device)\n","outputs = model(sample,labels=label)\n","_, logits = outputs\n","\n","pred = torch.argmax(F.softmax(logits), dim=1)\n","print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89i5eQ2U1tVc","executionInfo":{"status":"ok","timestamp":1642354017920,"user_tz":-540,"elapsed":1893,"user":{"displayName":"choi yerim","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08643437384388876422"}},"outputId":"2c594b39-61a4-43a8-9000-f331dcbb1d42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"]}]},{"cell_type":"code","source":["new_complaint=[\"\"]\n","seq=tokenizer.texts_to_sequences(new_complaint)\n","padded=pad_sequences(seq,maxlen=MAX_SEQUENCE_LENGTH)\n","pred=model.predict(padded)\n","print(np.argmax(pred))"],"metadata":{"id":"Q37AO3Fk1o2j"},"execution_count":null,"outputs":[]}]}